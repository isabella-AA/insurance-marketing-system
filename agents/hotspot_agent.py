import os
import time
import hashlib
import requests
from typing import List, Dict, Any, Optional
from urllib.parse import urljoin, urlparse
from datetime import datetime
from .base_agent import BaseAgent
from dotenv import load_dotenv

load_dotenv('config/.env')

class HotspotAgent(BaseAgent):
    """
    çƒ­ç‚¹æŠ“å–æ™ºèƒ½ä½“
    è´Ÿè´£ä»å¤šä¸ªå¹³å°æŠ“å–çƒ­ç‚¹äº‹ä»¶å¹¶å†™å…¥ESæ•°æ®åº“
    """
    
    def __init__(self):
        super().__init__("HotspotAgent")
        
        # é…ç½®å‚æ•°
        self.index_name = os.getenv("HOT_EVENT_INDEX", "hoteventdb")
        self.api_base_url = os.getenv("DAILY_HOT_API", "http://59.110.48.108:8888")
        self.request_timeout = int(os.getenv("REQUEST_TIMEOUT", 15))
        self.max_retries = int(os.getenv("MAX_RETRIES", 3))
        self.top_n = int(os.getenv("TOP_N_HOTSPOTS", 50))
        
        # å¹³å°é…ç½®
        self.platforms = {
            "weibo": {
                "endpoint": "/weibo",
                "name": "å¾®åšçƒ­æœ",
                "priority": 1,
                "enabled": True
            },
            "douyin": {
                "endpoint": "/douyin", 
                "name": "æŠ–éŸ³çƒ­ç‚¹",
                "priority": 2,
                "enabled": False  # å¯é…ç½®å¼€å¯
            },
            "toutiao": {
                "endpoint": "/toutiao",
                "name": "ä»Šæ—¥å¤´æ¡",
                "priority": 3,
                "enabled": True
            },
            "zhihu": {
                "endpoint": "/zhihu-daily",
                "name": "çŸ¥ä¹æ—¥æŠ¥", 
                "priority": 4,
                "enabled": False
            },
            "qq_news": {
                "endpoint": "/qq-news",
                "name": "è…¾è®¯æ–°é—»",
                "priority": 5,
                "enabled": False
            }
        }
        
        # å†…å®¹è¿‡æ»¤è§„åˆ™
        self.filter_rules = {
            "min_title_length": 5,
            "max_title_length": 200,
            "blacklist_keywords": [
                "å¹¿å‘Š", "æ¨å¹¿", "è¥é”€", "æµ‹è¯•", "spam"
            ],
            "required_elements": ["title", "url"]
        }
        
        # è¯·æ±‚é…ç½®
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Connection': 'keep-alive'
        }
        
        self.logger.info(f"âœ… çƒ­ç‚¹æŠ“å–å™¨åˆå§‹åŒ–å®Œæˆï¼Œç›®æ ‡å¹³å°: {len([p for p in self.platforms.values() if p['enabled']])} ä¸ª")
    
    def run_once(self) -> str:
        """
        æ‰§è¡Œä¸€æ¬¡çƒ­ç‚¹æŠ“å–ä»»åŠ¡
        
        Returns:
            å¤„ç†ç»“æœæè¿°
        """
        total_fetched = 0
        total_stored = 0
        platform_results = {}
        
        # è·å–å¯ç”¨çš„å¹³å°åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        enabled_platforms = [
            (key, config) for key, config in self.platforms.items() 
            if config["enabled"]
        ]
        enabled_platforms.sort(key=lambda x: x[1]["priority"])
        
        self.logger.info(f"ğŸš€ å¼€å§‹æŠ“å–çƒ­ç‚¹ï¼Œç›®æ ‡å¹³å°: {[p[1]['name'] for p in enabled_platforms]}")
        
        # é€ä¸ªå¹³å°æŠ“å–
        for platform_key, platform_config in enabled_platforms:
            try:
                self.logger.info(f"ğŸ” æ­£åœ¨æŠ“å– {platform_config['name']}")
                
                # æŠ“å–å¹³å°æ•°æ®
                platform_data = self._fetch_platform_data(platform_key, platform_config)
                
                if platform_data:
                    # å¤„ç†å’Œå­˜å‚¨æ•°æ®
                    stored_count = self._process_and_store_data(platform_data, platform_key)
                    
                    total_fetched += len(platform_data)
                    total_stored += stored_count
                    platform_results[platform_config['name']] = {
                        "æŠ“å–æ•°é‡": len(platform_data),
                        "å­˜å‚¨æ•°é‡": stored_count
                    }
                    
                    self.logger.info(f"âœ… {platform_config['name']} å®Œæˆ: æŠ“å– {len(platform_data)}, å­˜å‚¨ {stored_count}")
                else:
                    platform_results[platform_config['name']] = {"çŠ¶æ€": "æŠ“å–å¤±è´¥"}
                
                # å¹³å°é—´å»¶è¿Ÿï¼Œé¿å…é¢‘ç‡é™åˆ¶
                time.sleep(1)
                
            except Exception as e:
                self.logger.error(f"âŒ {platform_config['name']} æŠ“å–å¼‚å¸¸: {e}")
                platform_results[platform_config['name']] = {"çŠ¶æ€": f"å¼‚å¸¸: {str(e)[:50]}"}
        
        # æ¸…ç†æ—§æ•°æ®
        self._cleanup_old_data()
        
        result = f"çƒ­ç‚¹æŠ“å–å®Œæˆ: æ€»è®¡æŠ“å– {total_fetched}, æ–°å¢å­˜å‚¨ {total_stored}"
        self.logger.info(f"ğŸ“Š {result}")
        self.logger.info(f"ğŸ“‹ å¹³å°è¯¦æƒ…: {platform_results}")
        
        return result
    
    def _fetch_platform_data(self, platform_key: str, platform_config: Dict[str, Any]) -> Optional[List[Dict[str, Any]]]:
        """
        ä»æŒ‡å®šå¹³å°æŠ“å–æ•°æ®
        
        Args:
            platform_key: å¹³å°æ ‡è¯†
            platform_config: å¹³å°é…ç½®
            
        Returns:
            æŠ“å–åˆ°çš„æ•°æ®åˆ—è¡¨
        """
        url = f"{self.api_base_url}{platform_config['endpoint']}"
        
        for attempt in range(self.max_retries):
            try:
                self.logger.debug(f"ğŸ“¤ è¯·æ±‚ {platform_config['name']} (å°è¯• {attempt + 1}/{self.max_retries})")
                
                response = requests.get(
                    url,
                    headers=self.headers,
                    timeout=self.request_timeout
                )
                response.raise_for_status()
                
                data = response.json()
                
                # éªŒè¯å“åº”æ ¼å¼
                if not self._validate_response_format(data, platform_key):
                    self.logger.warning(f"âš ï¸ {platform_config['name']} å“åº”æ ¼å¼å¼‚å¸¸")
                    continue
                
                # æå–æ•°æ®
                items = data.get("data", [])
                if not items:
                    self.logger.warning(f"âš ï¸ {platform_config['name']} è¿”å›ç©ºæ•°æ®")
                    return []
                
                # é™åˆ¶æ•°é‡
                limited_items = items[:self.top_n]
                
                self.logger.debug(f"ğŸ“¥ {platform_config['name']} è·å– {len(limited_items)} æ¡æ•°æ®")
                return limited_items
                
            except requests.exceptions.Timeout:
                self.logger.warning(f"â° {platform_config['name']} è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1})")
                
            except requests.exceptions.ConnectionError:
                self.logger.warning(f"ğŸ”Œ {platform_config['name']} è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1})")
                
            except requests.exceptions.HTTPError as e:
                self.logger.error(f"âŒ {platform_config['name']} HTTPé”™è¯¯: {e}")
                break  # HTTPé”™è¯¯é€šå¸¸ä¸éœ€è¦é‡è¯•
                
            except Exception as e:
                self.logger.error(f"âŒ {platform_config['name']} æœªçŸ¥é”™è¯¯: {e}")
                break
            
            # é‡è¯•å»¶è¿Ÿ
            if attempt < self.max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        return None
    
    def _validate_response_format(self, data: Dict[str, Any], platform_key: str) -> bool:
        """
        éªŒè¯APIå“åº”æ ¼å¼
        
        Args:
            data: å“åº”æ•°æ®
            platform_key: å¹³å°æ ‡è¯†
            
        Returns:
            æ ¼å¼æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # åŸºæœ¬ç»“æ„æ£€æŸ¥
            if not isinstance(data, dict):
                return False
            
            if "data" not in data:
                return False
            
            items = data["data"]
            if not isinstance(items, list):
                return False
            
            # æ£€æŸ¥æ•°æ®é¡¹æ ¼å¼
            if items:
                sample_item = items[0]
                required_fields = self.filter_rules["required_elements"]
                
                for field in required_fields:
                    if field not in sample_item:
                        self.logger.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                        return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ å“åº”æ ¼å¼éªŒè¯å¼‚å¸¸: {e}")
            return False
    
    def _process_and_store_data(self, raw_data: List[Dict[str, Any]], platform_key: str) -> int:
        """
        å¤„ç†å¹¶å­˜å‚¨æ•°æ®
        
        Args:
            raw_data: åŸå§‹æ•°æ®
            platform_key: å¹³å°æ ‡è¯†
            
        Returns:
            å®é™…å­˜å‚¨çš„æ•°é‡
        """
        processed_items = []
        
        for item in raw_data:
            try:
                # æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–
                processed_item = self._process_single_item(item, platform_key)
                
                if processed_item and self._validate_item(processed_item):
                    processed_items.append(processed_item)
                    
            except Exception as e:
                self.logger.debug(f"âŒ å¤„ç†å•é¡¹æ•°æ®å¤±è´¥: {e}")
                continue
        
        # æ‰¹é‡å­˜å‚¨
        if processed_items:
            return self._batch_store_items(processed_items)
        else:
            return 0
    
    def _process_single_item(self, item: Dict[str, Any], platform_key: str) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†å•ä¸ªæ•°æ®é¡¹
        
        Args:
            item: åŸå§‹æ•°æ®é¡¹
            platform_key: å¹³å°æ ‡è¯†
            
        Returns:
            å¤„ç†åçš„æ•°æ®é¡¹
        """
        try:
            # æå–åŸºç¡€å­—æ®µ
            title = str(item.get("title", "")).strip()
            url = str(item.get("url", "")).strip()
            desc = str(item.get("desc", "")).strip()
            
            if not title or not url:
                return None
            
            # æ ‡é¢˜é•¿åº¦æ£€æŸ¥
            if len(title) < self.filter_rules["min_title_length"] or \
               len(title) > self.filter_rules["max_title_length"]:
                return None
            
            # é»‘åå•å…³é”®è¯æ£€æŸ¥
            title_lower = title.lower()
            if any(keyword in title_lower for keyword in self.filter_rules["blacklist_keywords"]):
                return None
            
            # URLæ ‡å‡†åŒ–
            normalized_url = self._normalize_url(url)
            
            # ç”Ÿæˆå”¯ä¸€ID
            unique_id = self._generate_unique_id(platform_key, title, normalized_url)
            
            # æ„å»ºæ ‡å‡†åŒ–æ•°æ®ç»“æ„
            processed_item = {
                "id": unique_id,
                "title": title,
                "url": normalized_url,
                "content": desc,
                "platform": platform_key,
                "platform_name": self.platforms[platform_key]["name"],
                "crawled_at": datetime.now().isoformat(),
                "rank": item.get("rank", 0),
                "hot_score": item.get("hot", 0),
                "extra_data": {
                    key: value for key, value in item.items() 
                    if key not in ["title", "url", "desc", "rank", "hot"]
                }
            }
            
            return processed_item
            
        except Exception as e:
            self.logger.debug(f"âŒ å•é¡¹å¤„ç†å¼‚å¸¸: {e}")
            return None
    
    def _validate_item(self, item: Dict[str, Any]) -> bool:
        """
        éªŒè¯å¤„ç†åçš„æ•°æ®é¡¹
        
        Args:
            item: å¤„ç†åçš„æ•°æ®é¡¹
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # å¿…è¦å­—æ®µæ£€æŸ¥
            required_fields = ["id", "title", "url", "platform", "crawled_at"]
            for field in required_fields:
                if field not in item or not item[field]:
                    return False
            
            # URLæœ‰æ•ˆæ€§æ£€æŸ¥
            if not self._is_valid_url(item["url"]):
                return False
            
            return True
            
        except Exception:
            return False
    
    def _normalize_url(self, url: str) -> str:
        """
        æ ‡å‡†åŒ–URL
        
        Args:
            url: åŸå§‹URL
            
        Returns:
            æ ‡å‡†åŒ–åçš„URL
        """
        try:
            # å¤„ç†ç›¸å¯¹URL
            if url.startswith("//"):
                url = "https:" + url
            elif url.startswith("/"):
                url = "https://weibo.com" + url  # é»˜è®¤å¾®åšåŸŸå
            elif not url.startswith(("http://", "https://")):
                url = "https://" + url
            
            # URLè§£æå’Œæ¸…ç†
            parsed = urlparse(url)
            
            # ç§»é™¤å¸¸è§çš„è·Ÿè¸ªå‚æ•°
            query_params_to_remove = ["utm_source", "utm_medium", "utm_campaign", "from", "share"]
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„URLæ¸…ç†é€»è¾‘
            
            return url
            
        except Exception:
            return url
    
    def _is_valid_url(self, url: str) -> bool:
        """
        æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            url: URLå­—ç¬¦ä¸²
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False
    
    def _generate_unique_id(self, platform: str, title: str, url: str) -> str:
        """
        ç”Ÿæˆå”¯ä¸€ID
        
        Args:
            platform: å¹³å°æ ‡è¯†
            title: æ ‡é¢˜
            url: URL
            
        Returns:
            å”¯ä¸€ID
        """
        # ä½¿ç”¨å¹³å°+æ ‡é¢˜+URLçš„ç»„åˆç”ŸæˆMD5å“ˆå¸Œ
        content = f"{platform}-{title}-{url}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def _batch_store_items(self, items: List[Dict[str, Any]]) -> int:
        """
        æ‰¹é‡å­˜å‚¨æ•°æ®é¡¹
        
        Args:
            items: æ•°æ®é¡¹åˆ—è¡¨
            
        Returns:
            å®é™…å­˜å‚¨çš„æ•°é‡
        """
        if not items:
            return 0
        
        try:
            # æ£€æŸ¥é‡å¤é¡¹
            new_items = []
            existing_count = 0
            
            for item in items:
                if not self.es.exists(self.index_name, item["id"]):
                    new_items.append(item)
                else:
                    existing_count += 1
            
            if existing_count > 0:
                self.logger.debug(f"ğŸ“‹ è·³è¿‡ {existing_count} ä¸ªå·²å­˜åœ¨çš„é¡¹ç›®")
            
            # æ‰¹é‡æ’å…¥æ–°é¡¹ç›®
            if new_items:
                doc_ids = [item["id"] for item in new_items]
                # ç§»é™¤idå­—æ®µï¼Œå› ä¸ºESä¼šè‡ªåŠ¨å¤„ç†
                docs_for_insert = []
                for item in new_items:
                    doc = item.copy()
                    doc.pop("id", None)
                    docs_for_insert.append(doc)
                
                success_count = self.es.bulk_index(
                    self.index_name, 
                    docs_for_insert, 
                    doc_ids
                )
                
                self.logger.debug(f"ğŸ’¾ æ‰¹é‡å­˜å‚¨å®Œæˆ: {success_count}/{len(new_items)} æˆåŠŸ")
                return success_count
            else:
                self.logger.debug("ğŸ“‹ æ²¡æœ‰æ–°æ•°æ®éœ€è¦å­˜å‚¨")
                return 0
                
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡å­˜å‚¨å¤±è´¥: {e}")
            return 0
    
    def _cleanup_old_data(self, days_to_keep: int = 7):
        """
        æ¸…ç†è¿‡æœŸæ•°æ®
        
        Args:
            days_to_keep: ä¿ç•™å¤©æ•°
        """
        try:
            # è®¡ç®—æˆªæ­¢æ—¥æœŸ
            from datetime import datetime, timedelta
            cutoff_date = (datetime.now() - timedelta(days=days_to_keep)).isoformat()
            
            # æŸ¥è¯¢è¿‡æœŸæ•°æ®
            query = {
                "range": {
                    "crawled_at": {
                        "lt": cutoff_date
                    }
                }
            }
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤é€»è¾‘ï¼Œä½†è¦è°¨æ…
            # å»ºè®®å…ˆç»Ÿè®¡æ•°é‡ï¼Œç¡®è®¤åå†åˆ é™¤
            old_count = self.es.count(self.index_name, query)
            
            if old_count > 0:
                self.logger.info(f"ğŸ—‘ï¸ å‘ç° {old_count} æ¡è¿‡æœŸæ•°æ® (>{days_to_keep}å¤©)")
                # å®é™…åˆ é™¤é€»è¾‘å¯ä»¥æ ¹æ®éœ€è¦å¼€å¯
                # self.es.delete_by_query(self.index_name, query)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
    
    def get_platform_status(self) -> Dict[str, Any]:
        """
        è·å–å¹³å°çŠ¶æ€ä¿¡æ¯
        
        Returns:
            å¹³å°çŠ¶æ€
        """
        status = {}
        
        for platform_key, platform_config in self.platforms.items():
            try:
                if platform_config["enabled"]:
                    # æµ‹è¯•å¹³å°è¿æ¥
                    url = f"{self.api_base_url}{platform_config['endpoint']}"
                    response = requests.get(url, headers=self.headers, timeout=5)
                    
                    if response.status_code == 200:
                        data = response.json()
                        item_count = len(data.get("data", []))
                        status[platform_config["name"]] = {
                            "çŠ¶æ€": "æ­£å¸¸",
                            "å¯ç”¨æ•°æ®": item_count,
                            "å“åº”æ—¶é—´": f"{response.elapsed.total_seconds():.2f}s"
                        }
                    else:
                        status[platform_config["name"]] = {
                            "çŠ¶æ€": f"å¼‚å¸¸ (HTTP {response.status_code})"
                        }
                else:
                    status[platform_config["name"]] = {"çŠ¶æ€": "å·²ç¦ç”¨"}
                    
            except Exception as e:
                status[platform_config["name"]] = {"çŠ¶æ€": f"è¿æ¥å¤±è´¥: {str(e)[:50]}"}
        
        return status
    
    def toggle_platform(self, platform_key: str, enabled: bool) -> bool:
        """
        å¯ç”¨/ç¦ç”¨å¹³å°
        
        Args:
            platform_key: å¹³å°æ ‡è¯†
            enabled: æ˜¯å¦å¯ç”¨
            
        Returns:
            æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        if platform_key in self.platforms:
            self.platforms[platform_key]["enabled"] = enabled
            status = "å¯ç”¨" if enabled else "ç¦ç”¨"
            self.logger.info(f"ğŸ”§ {status}å¹³å°: {self.platforms[platform_key]['name']}")
            return True
        else:
            self.logger.error(f"âŒ æœªçŸ¥å¹³å°: {platform_key}")
            return False
    
    def fetch_single_platform(self, platform_key: str) -> Dict[str, Any]:
        """
        å•ç‹¬æŠ“å–æŒ‡å®šå¹³å°
        
        Args:
            platform_key: å¹³å°æ ‡è¯†
            
        Returns:
            æŠ“å–ç»“æœ
        """
        if platform_key not in self.platforms:
            return {"error": f"æœªçŸ¥å¹³å°: {platform_key}"}
        
        platform_config = self.platforms[platform_key]
        
        try:
            self.logger.info(f"ğŸ¯ å•ç‹¬æŠ“å– {platform_config['name']}")
            
            # æŠ“å–æ•°æ®
            platform_data = self._fetch_platform_data(platform_key, platform_config)
            
            if platform_data:
                # å¤„ç†å’Œå­˜å‚¨
                stored_count = self._process_and_store_data(platform_data, platform_key)
                
                result = {
                    "platform": platform_config["name"],
                    "status": "æˆåŠŸ",
                    "fetched": len(platform_data),
                    "stored": stored_count,
                    "skipped": len(platform_data) - stored_count
                }
                
                self.logger.info(f"âœ… {platform_config['name']} å•ç‹¬æŠ“å–å®Œæˆ: {result}")
                return result
            else:
                return {
                    "platform": platform_config["name"],
                    "status": "å¤±è´¥",
                    "error": "æ•°æ®æŠ“å–å¤±è´¥"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ {platform_config['name']} å•ç‹¬æŠ“å–å¼‚å¸¸: {e}")
            return {
                "platform": platform_config["name"],
                "status": "å¼‚å¸¸",
                "error": str(e)
            }
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–æŠ“å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # æ€»æ•°ç»Ÿè®¡
            total_query = {"match_all": {}}
            total_count = self.es.count(self.index_name, total_query)
            
            # æŒ‰å¹³å°ç»Ÿè®¡
            platform_stats = {}
            for platform_key, platform_config in self.platforms.items():
                platform_query = {"term": {"platform": platform_key}}
                platform_count = self.es.count(self.index_name, platform_query)
                platform_stats[platform_config["name"]] = platform_count
            
            # ä»Šæ—¥æ–°å¢ç»Ÿè®¡
            from datetime import datetime, timedelta
            today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
            today_query = {
                "range": {
                    "crawled_at": {
                        "gte": today_start.isoformat()
                    }
                }
            }
            today_count = self.es.count(self.index_name, today_query)
            
            # çƒ­åº¦TOP10
            top_hot_query = {
                "match_all": {}
            }
            top_hot_events = self.es.search(
                self.index_name, 
                top_hot_query, 
                size=10,
                sort=[{"hot_score": {"order": "desc"}}]
            )
            
            return {
                "æ€»çƒ­ç‚¹æ•°é‡": total_count,
                "ä»Šæ—¥æ–°å¢": today_count,
                "å¹³å°åˆ†å¸ƒ": platform_stats,
                "å¹³å°çŠ¶æ€": {
                    name: "å¯ç”¨" if config["enabled"] else "ç¦ç”¨"
                    for name, config in [(config["name"], config) for config in self.platforms.values()]
                },
                "çƒ­åº¦TOP10": [
                    {
                        "æ ‡é¢˜": event.get("title", "")[:50],
                        "å¹³å°": event.get("platform_name", ""),
                        "çƒ­åº¦": event.get("hot_score", 0)
                    }
                    for event in top_hot_events[:10]
                ],
                "é…ç½®ä¿¡æ¯": {
                    "APIåœ°å€": self.api_base_url,
                    "æŠ“å–æ•°é‡": self.top_n,
                    "è¶…æ—¶æ—¶é—´": self.request_timeout,
                    "é‡è¯•æ¬¡æ•°": self.max_retries
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def search_hotspots(self, 
                       keyword: str, 
                       platform: Optional[str] = None,
                       limit: int = 20) -> List[Dict[str, Any]]:
        """
        æœç´¢çƒ­ç‚¹äº‹ä»¶
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            platform: æŒ‡å®šå¹³å°ï¼ˆå¯é€‰ï¼‰
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            query_conditions = [
                {"multi_match": {
                    "query": keyword,
                    "fields": ["title^2", "content"],
                    "type": "best_fields"
                }}
            ]
            
            if platform:
                query_conditions.append({"term": {"platform": platform}})
            
            search_query = {
                "bool": {
                    "must": query_conditions
                }
            }
            
            # æ‰§è¡Œæœç´¢
            results = self.es.search(
                self.index_name,
                search_query,
                size=limit,
                sort=[{"hot_score": {"order": "desc"}}, {"crawled_at": {"order": "desc"}}]
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for result in results:
                formatted_results.append({
                    "æ ‡é¢˜": result.get("title", ""),
                    "å¹³å°": result.get("platform_name", ""),
                    "URL": result.get("url", ""),
                    "å†…å®¹": result.get("content", "")[:100] + "..." if result.get("content") else "",
                    "çƒ­åº¦": result.get("hot_score", 0),
                    "æŠ“å–æ—¶é—´": result.get("crawled_at", ""),
                    "æ’å": result.get("rank", 0)
                })
            
            self.logger.info(f"ğŸ” æœç´¢å®Œæˆ: å…³é”®è¯='{keyword}', æ‰¾åˆ° {len(formatted_results)} æ¡ç»“æœ")
            return formatted_results
            
        except Exception as e:
            self.logger.error(f"âŒ æœç´¢çƒ­ç‚¹å¤±è´¥: {e}")
            return []