import os
from typing import List, Dict, Any, Optional
from .base_agent import BaseAgent
from utils.vector_utils import VectorUtils
from dotenv import load_dotenv

load_dotenv('config/.env')

class ProductMatcherAgent(BaseAgent):
    """
    äº§å“åŒ¹é…æ™ºèƒ½ä½“
    è´Ÿè´£æ ¹æ®é£é™©åˆ†æç»“æœåŒ¹é…åˆé€‚çš„ä¿é™©äº§å“
    """
    
    def __init__(self):
        super().__init__("ProductMatcher")
        
        # é…ç½®å‚æ•°
        self.event_index = os.getenv("HOT_EVENT_INDEX", "hoteventdb")
        self.product_index = os.getenv("PRODUCT_INDEX", "insurance-products")
        self.batch_size = int(os.getenv("PRODUCT_MATCHER_BATCH_SIZE", 5))
        self.top_k = int(os.getenv("TOP_K_PRODUCTS", 3))
        self.similarity_threshold = float(os.getenv("PRODUCT_SIMILARITY_THRESHOLD", 0.6))
        
        # åˆå§‹åŒ–å‘é‡å·¥å…·
        self.vector_utils = VectorUtils()
        
        # äº§å“å‘é‡ç¼“å­˜
        self.product_vectors = None
        self._load_products_with_vectors()
        
        # é£é™©-äº§å“ç±»åˆ«æ˜ å°„
        self.risk_product_mapping = {
            "å¥åº·é£é™©": ["é‡ç–¾é™©", "åŒ»ç–—é™©", "å¥åº·é™©"],
            "æ„å¤–ä¼¤å®³": ["æ„å¤–é™©", "ç»¼åˆæ„å¤–é™©"],
            "è´¢äº§æŸå¤±": ["è´¢äº§é™©", "å®¶è´¢é™©", "è½¦é™©"],
            "å‡ºè¡Œå®‰å…¨": ["æ„å¤–é™©", "æ—…æ¸¸é™©", "äº¤é€šæ„å¤–é™©"],
            "æ³•å¾‹è´£ä»»": ["è´£ä»»é™©", "èŒä¸šè´£ä»»é™©"],
            "ç«ç¾é£é™©": ["è´¢äº§é™©", "å®¶è´¢é™©"],
            "ç½‘ç»œå®‰å…¨": ["ç½‘ç»œå®‰å…¨é™©", "ä¿¡æ¯å®‰å…¨é™©"],
            "è‡ªç„¶ç¾å®³": ["è´¢äº§é™©", "ç¾å®³é™©"]
        }
        
        # äººç¾¤-äº§å“åŒ¹é…è§„åˆ™
        self.crowd_product_rules = {
            "è€å¹´äºº": {"age_max": 70, "preferred_categories": ["åŒ»ç–—é™©", "é‡ç–¾é™©", "æ„å¤–é™©"]},
            "å„¿ç«¥": {"age_max": 18, "preferred_categories": ["é‡ç–¾é™©", "åŒ»ç–—é™©", "æ•™è‚²é™©"]},
            "ä¸­å¹´äºº": {"age_range": [30, 55], "preferred_categories": ["é‡ç–¾é™©", "å¯¿é™©", "åŒ»ç–—é™©"]},
            "å¸æœº": {"occupation": "driver", "preferred_categories": ["æ„å¤–é™©", "è½¦é™©"]},
            "å­•å¦‡": {"special_group": "pregnant", "preferred_categories": ["æ¯å©´é™©", "åŒ»ç–—é™©"]},
            "æ¸¸å®¢": {"scenario": "travel", "preferred_categories": ["æ—…æ¸¸é™©", "æ„å¤–é™©"]},
            "ç—…æ‚£": {"health_condition": "sick", "preferred_categories": ["åŒ»ç–—é™©", "æŠ¤ç†é™©"]}
        }
        
        self.logger.info(f"âœ… äº§å“åŒ¹é…å™¨åˆå§‹åŒ–å®Œæˆï¼Œäº§å“æ•°é‡: {len(self.product_vectors) if self.product_vectors else 0}")
    
    def run_once(self) -> str:
        """
        æ‰§è¡Œä¸€æ¬¡äº§å“åŒ¹é…ä»»åŠ¡
        
        Returns:
            å¤„ç†ç»“æœæè¿°
        """
        # è·å–å¾…åŒ¹é…äº§å“çš„äº‹ä»¶
        events = self._fetch_events_for_matching()
        
        if not events:
            self.logger.info("âš ï¸ æš‚æ— å¾…åŒ¹é…äº§å“çš„äº‹ä»¶")
            return "æ— å¾…å¤„ç†äº‹ä»¶"
        
        # å¤„ç†äº‹ä»¶
        success_count = 0
        total_count = len(events)
        
        for event in events:
            try:
                if self._match_products_for_event(event):
                    success_count += 1
                    
            except Exception as e:
                self.logger.error(f"âŒ äº§å“åŒ¹é…å¤±è´¥: {event.get('title', 'Unknown')}, {e}")
        
        result = f"äº§å“åŒ¹é…å®Œæˆ: {success_count}/{total_count} æˆåŠŸ"
        self.logger.info(f"ğŸ“Š {result}")
        return result
    
    def _load_products_with_vectors(self):
        """åŠ è½½æ‰€æœ‰ä¿é™©äº§å“åŠå…¶å‘é‡"""
        try:
            # ä»ESåŠ è½½äº§å“æ•°æ®
            products = self.es.search(
                index=self.product_index,
                query={"match_all": {}},
                size=1000
            )
            
            if not products:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ä¿é™©äº§å“æ•°æ®")
                self.product_vectors = []
                return
            
            self.logger.info(f"ğŸ“¥ åŠ è½½äº† {len(products)} ä¸ªä¿é™©äº§å“")
            
            # æ„å»ºäº§å“æè¿°æ–‡æœ¬
            descriptions = []
            for product in products:
                desc_parts = []
                
                # æ·»åŠ äº§å“åç§°
                if product.get('product_name'):
                    desc_parts.append(product['product_name'])
                
                # æ·»åŠ ç±»åˆ«
                if product.get('category'):
                    desc_parts.append(product['category'])
                
                # æ·»åŠ é€‚ç”¨äººç¾¤
                if product.get('age_range'):
                    desc_parts.append(f"é€‚ç”¨å¹´é¾„:{product['age_range']}")
                
                # æ·»åŠ ä¿éšœå†…å®¹
                if product.get('coverage'):
                    desc_parts.append(product['coverage'])
                
                # æ·»åŠ ç‰¹è‰²æè¿°
                if product.get('features'):
                    desc_parts.append(product['features'])
                
                description = " ".join(desc_parts)
                descriptions.append(description)
            
            # æ‰¹é‡ç”Ÿæˆå‘é‡
            self.logger.info("ğŸ”„ æ­£åœ¨ç”Ÿæˆäº§å“å‘é‡...")
            vectors = self.vector_utils.embed_batch(descriptions, show_progress=True)
            
            # æ„å»ºäº§å“å‘é‡æ•°æ®
            self.product_vectors = []
            for i, product in enumerate(products):
                self.product_vectors.append({
                    "product": product,
                    "vector": vectors[i],
                    "description": descriptions[i]
                })
            
            self.logger.info(f"âœ… äº§å“å‘é‡ç”Ÿæˆå®Œæˆ: {len(self.product_vectors)} ä¸ª")
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½äº§å“å‘é‡å¤±è´¥: {e}")
            self.product_vectors = []
    
    def _fetch_events_for_matching(self) -> List[Dict[str, Any]]:
        """
        è·å–å¾…åŒ¹é…äº§å“çš„äº‹ä»¶
        
        Returns:
            äº‹ä»¶åˆ—è¡¨
        """
        try:
            query = {
                "bool": {
                    "must": [
                        {"term": {"risk_analyzed": True}},
                        {"exists": {"field": "risk_element"}}
                    ],
                    "must_not": [
                        {"exists": {"field": "recommended_products"}}
                    ]
                }
            }
            
            events = self.es.search(
                index=self.event_index,
                query=query,
                size=self.batch_size
            )
            
            self.logger.debug(f"ğŸ” è·å–åˆ° {len(events)} ä¸ªå¾…åŒ¹é…äº§å“çš„äº‹ä»¶")
            return events
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å¾…åŒ¹é…äº‹ä»¶å¤±è´¥: {e}")
            return []
    
    def _match_products_for_event(self, event: Dict[str, Any]) -> bool:
        """
        ä¸ºå•ä¸ªäº‹ä»¶åŒ¹é…äº§å“
        
        Args:
            event: äº‹ä»¶æ•°æ®
            
        Returns:
            æ˜¯å¦åŒ¹é…æˆåŠŸ
        """
        title = event.get("title", "")
        risk_element = event.get("risk_element", {})
        event_id = event.get("_id")
        
        if not risk_element:
            self.logger.warning(f"âš ï¸ äº‹ä»¶ç¼ºå°‘é£é™©è¦ç´ : {event_id}")
            return False
        
        crowd_type = risk_element.get("æ¶‰åŠäººç¾¤", "")
        risk_type = risk_element.get("é£é™©ç±»å‹", "")
        
        self.logger.info(f"ğŸ¯ æ­£åœ¨åŒ¹é…äº§å“: {title[:50]}... (äººç¾¤:{crowd_type}, é£é™©:{risk_type})")
        
        # æ‰§è¡Œäº§å“åŒ¹é…
        matched_products = self._perform_product_matching(crowd_type, risk_type, title)
        
        if matched_products:
            # æ›´æ–°äº‹ä»¶è®°å½•
            return self._update_event_products(event_id, matched_products)
        else:
            self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„äº§å“: {title}")
            # æ ‡è®°ä¸ºå·²å¤„ç†ä½†æ— åŒ¹é…ç»“æœ
            return self._mark_no_match(event_id)
    
    def _perform_product_matching(self, crowd_type: str, risk_type: str, title: str) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œäº§å“åŒ¹é…é€»è¾‘
        
        Args:
            crowd_type: äººç¾¤ç±»å‹
            risk_type: é£é™©ç±»å‹
            title: äº‹ä»¶æ ‡é¢˜
            
        Returns:
            åŒ¹é…çš„äº§å“åˆ—è¡¨
        """
        if not self.product_vectors:
            self.logger.warning("âš ï¸ äº§å“å‘é‡æ•°æ®æœªåŠ è½½")
            return []
        
        try:
            # 1. åŸºäºè§„åˆ™çš„åˆæ­¥ç­›é€‰
            rule_candidates = self._filter_by_rules(crowd_type, risk_type)
            
            # 2. åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„ç²¾ç¡®åŒ¹é…
            vector_candidates = self._match_by_vector_similarity(crowd_type, risk_type, title)
            
            # 3. åˆå¹¶å’Œé‡æ’åºç»“æœ
            final_matches = self._merge_and_rank_candidates(rule_candidates, vector_candidates)
            
            # 4. ç”ŸæˆåŒ¹é…ç†ç”±
            enriched_matches = self._enrich_with_reasons(final_matches, crowd_type, risk_type)
            
            return enriched_matches[:self.top_k]
            
        except Exception as e:
            self.logger.error(f"âŒ äº§å“åŒ¹é…å¼‚å¸¸: {e}")
            return []
    
    def _filter_by_rules(self, crowd_type: str, risk_type: str) -> List[Dict[str, Any]]:
        """
        åŸºäºè§„åˆ™ç­›é€‰å€™é€‰äº§å“
        
        Args:
            crowd_type: äººç¾¤ç±»å‹
            risk_type: é£é™©ç±»å‹
            
        Returns:
            å€™é€‰äº§å“åˆ—è¡¨
        """
        candidates = []
        
        # è·å–é£é™©å¯¹åº”çš„äº§å“ç±»åˆ«
        preferred_categories = self.risk_product_mapping.get(risk_type, [])
        
        # è·å–äººç¾¤åå¥½çš„äº§å“ç±»åˆ«
        crowd_rules = self.crowd_product_rules.get(crowd_type, {})
        crowd_categories = crowd_rules.get("preferred_categories", [])
        
        # åˆå¹¶ç±»åˆ«åå¥½
        target_categories = list(set(preferred_categories + crowd_categories))
        
        for product_item in self.product_vectors:
            product = product_item["product"]
            product_category = product.get("category", "")
            
            # æ£€æŸ¥ç±»åˆ«åŒ¹é…
            category_match = any(cat in product_category for cat in target_categories)
            
            # æ£€æŸ¥äººç¾¤é€‚ç”¨æ€§
            crowd_match = self._check_crowd_suitability(product, crowd_type)
            
            if category_match or crowd_match:
                score = 0
                if category_match:
                    score += 0.7
                if crowd_match:
                    score += 0.3
                
                candidates.append({
                    "product": product,
                    "score": score,
                    "match_type": "rule",
                    "vector": product_item["vector"]
                })
        
        # æŒ‰è¯„åˆ†æ’åº
        candidates.sort(key=lambda x: x["score"], reverse=True)
        
        self.logger.debug(f"ğŸ“‹ è§„åˆ™ç­›é€‰å¾—åˆ° {len(candidates)} ä¸ªå€™é€‰äº§å“")
        return candidates
    
    def _match_by_vector_similarity(self, crowd_type: str, risk_type: str, title: str) -> List[Dict[str, Any]]:
        """
        åŸºäºå‘é‡ç›¸ä¼¼åº¦åŒ¹é…äº§å“
        
        Args:
            crowd_type: äººç¾¤ç±»å‹
            risk_type: é£é™©ç±»å‹
            title: äº‹ä»¶æ ‡é¢˜
            
        Returns:
            åŒ¹é…çš„äº§å“åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢æ–‡æœ¬
            query_parts = []
            if crowd_type and crowd_type != "ä¸€èˆ¬äººç¾¤":
                query_parts.append(crowd_type)
            if risk_type and risk_type != "æ— æ˜æ˜¾é£é™©":
                query_parts.append(risk_type)
            if title:
                query_parts.append(title[:50])  # é™åˆ¶æ ‡é¢˜é•¿åº¦
            
            query_text = " ".join(query_parts)
            
            if not query_text.strip():
                return []
            
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vector = self.vector_utils.embed(query_text)
            
            # è®¡ç®—ä¸æ‰€æœ‰äº§å“çš„ç›¸ä¼¼åº¦
            similarities = []
            for product_item in self.product_vectors:
                similarity = self.vector_utils.cosine_similarity(
                    query_vector, 
                    product_item["vector"]
                )
                
                if similarity >= self.similarity_threshold:
                    similarities.append({
                        "product": product_item["product"],
                        "score": similarity,
                        "match_type": "vector",
                        "vector": product_item["vector"]
                    })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            similarities.sort(key=lambda x: x["score"], reverse=True)
            
            self.logger.debug(f"ğŸ” å‘é‡åŒ¹é…å¾—åˆ° {len(similarities)} ä¸ªå€™é€‰äº§å“")
            return similarities
            
        except Exception as e:
            self.logger.error(f"âŒ å‘é‡ç›¸ä¼¼åº¦åŒ¹é…å¤±è´¥: {e}")
            return []
    
    def _check_crowd_suitability(self, product: Dict[str, Any], crowd_type: str) -> bool:
        """
        æ£€æŸ¥äº§å“æ˜¯å¦é€‚åˆç‰¹å®šäººç¾¤
        
        Args:
            product: äº§å“ä¿¡æ¯
            crowd_type: äººç¾¤ç±»å‹
            
        Returns:
            æ˜¯å¦é€‚åˆ
        """
        age_range = product.get("age_range", "")
        features = product.get("features", "")
        coverage = product.get("coverage", "")
        
        # æ–‡æœ¬åŒ¹é…æ£€æŸ¥
        text_content = f"{age_range} {features} {coverage}".lower()
        crowd_keywords = {
            "è€å¹´äºº": ["è€å¹´", "è€äºº", "é•¿è€…", "50", "60", "70"],
            "å„¿ç«¥": ["å„¿ç«¥", "å°å­©", "å­©å­", "å­¦ç”Ÿ", "18å²ä»¥ä¸‹"],
            "ä¸­å¹´äºº": ["ä¸­å¹´", "æˆå¹´", "30-60", "èŒåœº"],
            "å¸æœº": ["å¸æœº", "é©¾é©¶", "è½¦ä¸»", "å¼€è½¦"],
            "å­•å¦‡": ["å­•å¦‡", "å­•æœŸ", "æ¯å©´", "ç”Ÿè‚²"],
            "æ¸¸å®¢": ["æ—…æ¸¸", "å‡ºè¡Œ", "æ—…å®¢"],
            "ç—…æ‚£": ["åŒ»ç–—", "å¥åº·", "ç–¾ç—…", "æ²»ç–—"]
        }
        
        keywords = crowd_keywords.get(crowd_type, [])
        return any(keyword in text_content for keyword in keywords)
    
    def _merge_and_rank_candidates(self, rule_candidates: List[Dict], vector_candidates: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶å’Œé‡æ’åºå€™é€‰äº§å“
        
        Args:
            rule_candidates: è§„åˆ™ç­›é€‰çš„å€™é€‰äº§å“
            vector_candidates: å‘é‡åŒ¹é…çš„å€™é€‰äº§å“
            
        Returns:
            åˆå¹¶åçš„å€™é€‰äº§å“åˆ—è¡¨
        """
        # ä½¿ç”¨äº§å“IDå»é‡
        product_scores = {}
        
        # å¤„ç†è§„åˆ™å€™é€‰äº§å“
        for candidate in rule_candidates:
            product_id = candidate["product"].get("_id") or candidate["product"].get("product_name")
            if product_id not in product_scores:
                product_scores[product_id] = {
                    "product": candidate["product"],
                    "rule_score": candidate["score"],
                    "vector_score": 0,
                    "vector": candidate["vector"]
                }
            else:
                product_scores[product_id]["rule_score"] = max(
                    product_scores[product_id]["rule_score"], 
                    candidate["score"]
                )
        
        # å¤„ç†å‘é‡å€™é€‰äº§å“
        for candidate in vector_candidates:
            product_id = candidate["product"].get("_id") or candidate["product"].get("product_name")
            if product_id not in product_scores:
                product_scores[product_id] = {
                    "product": candidate["product"],
                    "rule_score": 0,
                    "vector_score": candidate["score"],
                    "vector": candidate["vector"]
                }
            else:
                product_scores[product_id]["vector_score"] = max(
                    product_scores[product_id]["vector_score"], 
                    candidate["score"]
                )
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        final_candidates = []
        for product_id, data in product_scores.items():
            # ç»¼åˆè¯„åˆ†ï¼šè§„åˆ™æƒé‡0.4ï¼Œå‘é‡æƒé‡0.6
            combined_score = data["rule_score"] * 0.4 + data["vector_score"] * 0.6
            
            final_candidates.append({
                "product": data["product"],
                "combined_score": combined_score,
                "rule_score": data["rule_score"],
                "vector_score": data["vector_score"]
            })
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        final_candidates.sort(key=lambda x: x["combined_score"], reverse=True)
        
        self.logger.debug(f"ğŸ”€ åˆå¹¶åå¾—åˆ° {len(final_candidates)} ä¸ªå€™é€‰äº§å“")
        return final_candidates
    
    def _enrich_with_reasons(self, candidates: List[Dict], crowd_type: str, risk_type: str) -> List[Dict]:
        """
        ä¸ºåŒ¹é…ç»“æœæ·»åŠ æ¨èç†ç”±
        
        Args:
            candidates: å€™é€‰äº§å“åˆ—è¡¨
            crowd_type: äººç¾¤ç±»å‹
            risk_type: é£é™©ç±»å‹
            
        Returns:
            enrichedäº§å“åˆ—è¡¨
        """
        enriched = []
        
        for candidate in candidates:
            product = candidate["product"]
            rule_score = candidate.get("rule_score", 0)
            vector_score = candidate.get("vector_score", 0)
            
            # ç”Ÿæˆæ¨èç†ç”±
            reasons = []
            
            # åŸºäºäººç¾¤åŒ¹é…çš„ç†ç”±
            if crowd_type and crowd_type != "ä¸€èˆ¬äººç¾¤":
                if self._check_crowd_suitability(product, crowd_type):
                    reasons.append(f"ä¸“ä¸º{crowd_type}è®¾è®¡")
            
            # åŸºäºé£é™©åŒ¹é…çš„ç†ç”±
            if risk_type and risk_type != "æ— æ˜æ˜¾é£é™©":
                product_category = product.get("category", "")
                preferred_categories = self.risk_product_mapping.get(risk_type, [])
                if any(cat in product_category for cat in preferred_categories):
                    reasons.append(f"é’ˆå¯¹{risk_type}æä¾›ä¿éšœ")
            
            # åŸºäºè¯„åˆ†çš„ç†ç”±
            if rule_score > 0.5:
                reasons.append("ç¬¦åˆä¸“ä¸šæ¨èè§„åˆ™")
            if vector_score > 0.7:
                reasons.append("ä¸äº‹ä»¶é«˜åº¦ç›¸å…³")
            
            # å¦‚æœæ²¡æœ‰å…·ä½“ç†ç”±ï¼Œæ·»åŠ é€šç”¨ç†ç”±
            if not reasons:
                reasons.append("ç»¼åˆè¯„ä¼°æ¨è")
            
            enriched.append({
                "äº§å“åç§°": product.get("product_name", ""),
                "äº§å“ç±»åˆ«": product.get("category", ""),
                "ä¿éšœå†…å®¹": product.get("coverage", ""),
                "é€‚ç”¨äººç¾¤": product.get("age_range", ""),
                "æ¨èç†ç”±": "ï¼›".join(reasons),
                "åŒ¹é…è¯„åˆ†": round(candidate["combined_score"], 3)
            })
        
        return enriched
    
    def _update_event_products(self, event_id: str, products: List[Dict[str, Any]]) -> bool:
        """
        æ›´æ–°äº‹ä»¶çš„æ¨èäº§å“ä¿¡æ¯
        
        Args:
            event_id: äº‹ä»¶ID
            products: æ¨èäº§å“åˆ—è¡¨
            
        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            update_data = {
                "recommended_products": products,
                "product_matched": True
            }
            
            success = self.es.update_by_id(
                index=self.event_index,
                doc_id=event_id,
                doc=update_data
            )
            
            if success:
                self.logger.info(f"âœ… äº§å“æ¨èå·²æ›´æ–°: {event_id}, æ¨è {len(products)} æ¬¾äº§å“")
                return True
            else:
                self.logger.error(f"âŒ äº§å“æ¨èæ›´æ–°å¤±è´¥: {event_id}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°äº§å“æ¨èå¼‚å¸¸: {event_id}, {e}")
            return False
    
    def _mark_no_match(self, event_id: str) -> bool:
        """
        æ ‡è®°æ— åŒ¹é…äº§å“
        
        Args:
            event_id: äº‹ä»¶ID
            
        Returns:
            æ ‡è®°æ˜¯å¦æˆåŠŸ
        """
        try:
            update_data = {
                "recommended_products": [],
                "product_matched": True,
                "no_product_match": True
            }
            
            return self.es.update_by_id(
                index=self.event_index,
                doc_id=event_id,
                doc=update_data
            )
            
        except Exception as e:
            self.logger.error(f"âŒ æ ‡è®°æ— åŒ¹é…äº§å“å¼‚å¸¸: {event_id}, {e}")
            return False
    
    def refresh_product_vectors(self):
        """åˆ·æ–°äº§å“å‘é‡ç¼“å­˜"""
        self.logger.info("ğŸ”„ åˆ·æ–°äº§å“å‘é‡ç¼“å­˜...")
        self._load_products_with_vectors()
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–äº§å“åŒ¹é…ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # ç»Ÿè®¡å·²åŒ¹é…çš„äº‹ä»¶æ•°é‡
            matched_query = {"term": {"product_matched": True}}
            matched_count = self.es.count(self.event_index, matched_query)
            
            # ç»Ÿè®¡æ— åŒ¹é…çš„äº‹ä»¶æ•°é‡
            no_match_query = {"term": {"no_product_match": True}}
            no_match_count = self.es.count(self.event_index, no_match_query)
            
            # ç»Ÿè®¡å¾…å¤„ç†çš„äº‹ä»¶æ•°é‡
            pending_query = {
                "bool": {
                    "must": [
                        {"term": {"risk_analyzed": True}},
                        {"exists": {"field": "risk_element"}}
                    ],
                    "must_not": [
                        {"exists": {"field": "recommended_products"}}
                    ]
                }
            }
            pending_count = self.es.count(self.event_index, pending_query)
            
            return {
                "total_products": len(self.product_vectors) if self.product_vectors else 0,
                "matched_events": matched_count,
                "no_match_events": no_match_count,
                "pending_events": pending_count,
                "match_success_rate": round(matched_count / (matched_count + no_match_count), 2) if (matched_count + no_match_count) > 0 else 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}